import hashlib
import uuid
import re
import requests
import urllib3
import os
import tempfile
import json
import pandas as pd
from datetime import datetime
from pymongo import MongoClient
from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.responses import JSONResponse
from elasticsearch import Elasticsearch, helpers


try:
    from deepguard_crawl_b2b import main_controller
except ImportError:
    
    print("âš ï¸ ê²½ê³ : 'deepguard_crawl_b2b' ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("âš ï¸ ì„ì‹œ í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
    
    def main_controller(target):
        # í¬ë¡¤ëŸ¬ íŒŒì¼ì´ ì—†ì„ ë•Œ ì—ëŸ¬ ì•ˆ ë‚˜ê²Œ í•´ì£¼ëŠ” ê°€ì§œ ì‘ë‹µ
        return {
            "id": str(uuid.uuid4()),
            "target_email": target,
            "status": "Test Mode (Crawler Not Found)",
            "leaked_date": str(datetime.now()),
            "source": "Test Source"
        }

app = FastAPI()

# ---------------------------------------------------------
# DB ì—°ê²° ì„¤ì •
# ---------------------------------------------------------
# Elasticsearch ì—°ê²°
es = Elasticsearch(
    "http://localhost:9200",
    verify_certs=False
)

# MongoDB ì—°ê²°
try:
    mongo_client = MongoClient("mongodb://localhost:27017/")
    mongo_db = mongo_client["deepguard_db"]
    mongo_collection = mongo_db["leaked_data"]
    print("âœ… MongoDB Connected")
except Exception as e:
    print(f"âš ï¸ MongoDB Connection Failed: {e}")



def load_file_to_dataframe(file_path, content_type):
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()
    
    if ext == '.csv' or content_type == 'text/csv':
        df = pd.read_csv(file_path)
    elif ext == '.tsv' or content_type == 'text/tab-separated-values':
        df = pd.read_csv(file_path, sep='\t')
    elif ext == '.json' or content_type == 'application/json':
        df = pd.read_json(file_path)
    elif ext == '.ndjson':
        df = pd.read_json(file_path, lines=True)
    else:
        return pd.DataFrame() # ë¹ˆ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜
    
    return df.fillna('')

def doc_generator(df, index_name):
    for index, row in df.iterrows():
        yield {
            "_index": index_name,
            "_source": row.to_dict()
        }

@app.post("/upload")
async def upload_to_elasticsearch(
    file: UploadFile = File(...),
    index_name: str = None
):
    """ì¼ë°˜ íŒŒì¼ ì—…ë¡œë“œ API (ê¸°ì¡´ ìœ ì§€)"""
    try:
        if index_name is None:
            index_name = os.path.splitext(file.filename)[0]
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(file.filename)[1]) as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        df = load_file_to_dataframe(tmp_file_path, file.content_type)
        
        success, failed = helpers.bulk(es, doc_generator(df, index_name))
        os.unlink(tmp_file_path)
        
        return JSONResponse(
            status_code=200,
            content={"message": "ì—…ë¡œë“œ ì„±ê³µ", "success": success, "failed": failed}
        )
    except Exception as e:
        if 'tmp_file_path' in locals(): os.unlink(tmp_file_path)
        raise HTTPException(status_code=500, detail=str(e))



@app.post("/analyze-file")
async def analyze_uploaded_file(file: UploadFile = File(...)):
  
    # 1. íŒŒì¼ ì½ê¸°
    content = await file.read()
    try:
        text_data = content.decode("utf-8")
    except:
        text_data = content.decode("cp949", errors="ignore")

    results = []
    lines = text_data.splitlines()
    
    for line in lines:
        line = line.strip()
        if not line: continue
        
        # 2. íŒŒì¼ íŒŒì‹± (ì´ë©”ì¼:ë¹„ë²ˆ í˜•ì‹ ë¶„ë¦¬)
        if ":" in line:
            parts = line.split(":")
            target_email = ""
            
            # ì´ë©”ì¼ ì°¾ê¸°
            for part in parts:
                if "@" in part and "." in part:
                    target_email = part.strip()
                    break
            
            # ì´ë©”ì¼ì´ ì¡´ì¬í•˜ë©´ í¬ë¡¤ëŸ¬ ê°€ë™
            if target_email:
                try:
                    # =========================================================
                    
                    # ê°€ì§œ entry ìƒì„± ë¡œì§ ì‚­ì œ -> í¬ë¡¤ëŸ¬ ê²°ê³¼ê°’(JSON) ìˆ˜ì‹ 
                    # =========================================================
                    print(f"ğŸ“¡ í¬ë¡¤ëŸ¬ ë¶„ì„ ìš”ì²­: {target_email}")
                    
                    # ì—¬ê¸°ì„œ deepguard_crawl_b2b.pyì˜ í•¨ìˆ˜ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤.
                    crawled_data = main_controller(target_email)
                    
                    # í¬ë¡¤ëŸ¬ê°€ ë°ì´í„°ë¥¼ ì˜ ì¤¬ëŠ”ì§€ í™•ì¸ (ë”•ì…”ë„ˆë¦¬ í˜•íƒœì—¬ì•¼ í•¨)
                    if isinstance(crawled_data, dict):
                        # ì›ë³¸ ë¼ì¸ ì •ë³´ê°€ í•„ìš”í•˜ë©´ ì¶”ê°€ (ì„ íƒì‚¬í•­)
                        crawled_data["raw_line_text"] = line
                        
                        # -----------------------------------------------------
                        
                        # -----------------------------------------------------
                        
                        # 1. MongoDB ì ì¬
                        if 'mongo_collection' in globals():
                            # _id ì¶©ëŒ ë°©ì§€ë¥¼ ìœ„í•´ copy() ì‚¬ìš©
                            mongo_collection.insert_one(crawled_data.copy())
                        
                        # 2. Elasticsearch ì ì¬
                        # ESëŠ” _idê°€ ë³¸ë¬¸ ì•ˆì— ìˆìœ¼ë©´ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¶„ë¦¬
                        es_body = crawled_data.copy()
                        es_id = es_body.pop("_id", str(uuid.uuid4())) # _idê°€ ìˆìœ¼ë©´ ë¹¼ì„œ ì“°ê³ , ì—†ìœ¼ë©´ ë§Œë“¦
                        
                        es.index(index="leaked_data", id=str(es_id), body=es_body)
                        
                        # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                        results.append(crawled_data)
                    else:
                        print(f"âš ï¸ í¬ë¡¤ëŸ¬ ë°˜í™˜ ë°ì´í„° ì˜¤ë¥˜: {crawled_data}")

                except Exception as e:
                    print(f"âŒ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
                    # ì—ëŸ¬ê°€ ë‚˜ë„ ë©ˆì¶”ì§€ ì•Šê³  ë‹¤ìŒ ì¤„ë¡œ ë„˜ì–´ê°

    return {
        "status": "success",
        "file_name": file.filename,
        "total_processed": len(results),
        "data": results
    }

# ---------------------------------------------------------
# ìƒíƒœ í™•ì¸ìš© API (í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™ìš©)
# ---------------------------------------------------------
@app.get("/")
async def root():
    return {"message": "DeepGuard Backend Running"}

@app.get("/health")
async def health_check():
    return {"status": "ok", "elasticsearch": "connected" if es.ping() else "disconnected"}

# ê²€ìƒ‰ ê¸°ëŠ¥ë“¤ (ê¸°ì¡´ ìœ ì§€)
@app.get("/search/{index_name}")
async def search_data(index_name: str, query: str):
    res = es.search(index=index_name, body={"query": {"multi_match": {"query": query, "fields": ["*"]}}})
    return res['hits']['hits']